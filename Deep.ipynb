{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicoweber95/DeepRitzMethod/blob/master/Deep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AZshiOJuJ2l",
        "colab_type": "text"
      },
      "source": [
        "We want solve the following Dirichlet boundary problem: \\\\\n",
        "$-\\Delta u = 0$ in $\\Omega$ \\\\\n",
        "$u = 0$ in $\\partial \\Omega$ \\\\\n",
        "$\\Omega$ = \\{ x  $\\in$ $\\mathbb{R}^n$  | $\\sum_{i=1}^{n} x_i^2 \\leq 1$} \\\\\n",
        "exact solution: $\\frac{1}{2n}(\\sum_{i=1}^{n} x_i^2 -1 )$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fth1SRAMrEH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from __future__import absolute_import, division, print_function, unicode_literals\n",
        "#example 3.1: The Poisson equation in two dimensions\n",
        "try:\n",
        "  # default tensorflow is 1.15\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import numpy as np\n",
        "from numpy import linalg as LA\n",
        "import itertools as it\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import tensorflow as tf\n",
        "# backend: create own activation functions, layers\n",
        "from keras import backend as K \n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from kers import Model\n",
        "\n",
        "class RitzNet(Model):\n",
        "  def __init__(self,m,dim):\n",
        "    super(RitzNet, self).__init__()\n",
        "    self.m = m\n",
        "    self.dim = dim\n",
        "# test example for dimension 2,3 and 8; For later: make dimension variabel\n",
        "    if self.dim == 2:\n",
        "      self.l1 = Dense(m, activation = a_three)\n",
        "      self.l2 = Dense(m, activation = a_three)\n",
        "      self.l3 = Dense(m, activation = a_three)\n",
        "    elif seld.dim ==3:\n",
        "      self.l1 = Dense(m, activation = a_three)\n",
        "      self.l2 = Dense(m, activation = a_three)\n",
        "      self.l3 = Dense(m, activation = a_three)\n",
        "      self.l4 = Dense(m, activation = a_three)\n",
        "    elif self.dim == 8:\n",
        "      self.l1 = Dense(m, activation = a_three)\n",
        "      self.l2 = Dense(m, activation = a_three)\n",
        "      self.l3 = Dense(m, activation = a_three)\n",
        "      self.l4 = Dense(m, activation = a_three)\n",
        "      self.l5 = Dense(m, activation = a_three)\n",
        "  def call(self,x):\n",
        "    if self.dim == 2:\n",
        "      x = self.l1(x)\n",
        "      x = self.l2(x)\n",
        "      return  self.l3(x)\n",
        "    elif seld.dim ==3:\n",
        "      x = self.l1(x)\n",
        "      x = self.l2(x)\n",
        "      x = self.l3(x)\n",
        "      return  self.l4(x)\n",
        "    elif self.dim == 8:\n",
        "      x = self.l1(x)\n",
        "      x = self.l2(x)\n",
        "      x = self.l3(x)\n",
        "      x = self.l4(x)\n",
        "      return  self.l5(x)\n",
        "\n",
        "#define own activation function \n",
        "def a_three(x):\n",
        "  return K.ReLU \n",
        "  #return K.ReLU(np.power(x,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKpD27wPYW9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exact_function(x,n):\n",
        "  func = np.zeros(1)\n",
        "  for i in range(0,n):\n",
        "    func += x[i]**2\n",
        "  func += -1\n",
        "  func /= (2*n)\n",
        "  return func\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4eicNEkFKFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# question: cann loss fm/keras-team/keras/issues/2121#issuecomment-214551349\n",
        "def penalized_loss\n",
        "#(unction only take two argumensts\n",
        "# see https://github.cosample_strategy):\n",
        "    def loss(y_true, y_pred):\n",
        "        return K.mean(K.square(y_pred - y_true) - K.square(y_true - noise), axis=-1)\n",
        "    return loss\n",
        "\n",
        "\n",
        "input1 = Input(batch_shape=(batch_size, timesteps, features))\n",
        "lstm =  LSTM(features, stateful=True, return_sequences=True)(input1)\n",
        "output1 = TimeDistributed(Dense(features, activation='sigmoid'))(lstm)\n",
        "output2 = TimeDistributed(Dense(features, activation='sigmoid'))(lstm)\n",
        "model = Model(input=[input1], output=[output1, output2])\n",
        "model.compile(loss=[penalized_loss(noise=output2), penalized_loss(noise=output1)], optimizer='rmsprop')\n",
        "def cal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKEdOOj3KHRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(model,x_in,x_out):\n",
        "  dim_in = x_in.shape[0]\n",
        "  dim_out = x_out.shape[0]\n",
        "  eps = 0.0001\n",
        "  x_grad = np.zeros(dim_in)\n",
        "  for j in it.product(*map(range,x_in.shape[1:])):\n",
        "    y = model([x_in[i][j] for i in range(dim_in)],dimension)\n",
        "    \n",
        "    print(y_in[j])\n",
        "  for in in range(dim_in):\n",
        "    x = x_in[i]\n",
        "  x1 = torch.zeros(m)\n",
        "                x2 = torch.zeros(m)\n",
        "                x1[0] = 0.0001\n",
        "                x2[1] = 0.0001\n",
        "                x_input_1 = x_input.float() + x1\n",
        "                x_input_2 = x_input.float() + x2\n",
        "                x_input_3 = x_input.float() - x1\n",
        "                x_input_4 = x_input.float() - x2\n",
        "                x_input_grad_1 = (model(x_input_1) - y) / 0.0001\n",
        "                x_input_grad_2 = (model(x_input_2) - y) / 0.0001\n",
        "                x_input_2_grad_x = (model(x_input_1) + model(x_input_3) - 2 * y) / 0.0001**2\n",
        "                x_input_2_grad_y = (model(x_input_2) + model(x_input_4) - 2 * y) / 0.0001**2\n",
        "\n",
        "                loss += 0.5 * ((x_input_grad_1) ** 2 + (x_input_grad_2) ** 2) - y \n",
        "    loss /= n1\n",
        "  # points should be a n*n Matrix\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCIH6vwx4zFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://towardsdatascience.com/tensorflow-2-0-create-and-train-a-vanilla-cnn-on-google-colab-c7a0ac86d61b\n",
        "@tf.function\n",
        "def train_step(x_in,x_out):\n",
        "  with tf.GradientTape() as tape:\n",
        "    prediction1 = model(x_in)\n",
        "    prediction2 = model(x_out)\n",
        "    loss = custom_loss(prediction1, prediction2)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  #optimizer = tf.keras.optimizers.SGD\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cpZ6q7_NdWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data(x_in,x_out):\n",
        "  dimension = x_in.shape[0]\n",
        "  y_in  = np.zeros(x_in.shape[1:])\n",
        "    #for i in range(dimension):\n",
        "  for j in it.product(*map(range,x_in.shape[1:])):\n",
        "    print(42)\n",
        "    print([x_in[i][j] for i in range(dimension)])\n",
        "    y_in[j] = exact_function([x_in[i][j] for i in range(dimension)],dimension)\n",
        "    print(y_in[j])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcGaJ0MZOxeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcNYmb6nZsVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grid_sampling(type,dim,n_in,n_b):\n",
        "#type: 0: uniform sampling, 1: random sampling\n",
        "#dim: dimension of domain\n",
        "#n_in: number points in domain interior for each dimension ( n_in*dim all in all)\n",
        "#n_out: number points on boundary for each dimension (n_out*dim all in all)\n",
        "#idea boundary: take the boundary [-1,1]^dim and normalize to one\n",
        "#example :x= grid_sampling(0,2,2,3)\n",
        "#print(x[0])\n",
        "#print(x[1])\n",
        "#[array([[-1.,  0.],\n",
        " #      [-1.,  0.]]), array([[-1., -1.],\n",
        "  #     [ 0.,  0.]])]\n",
        "#[[[-0.70710678  0.          0.70710678]\n",
        " # [-1.          0.          1.        ]\n",
        "  #[-0.70710678  0.          0.70710678]]\n",
        "\n",
        " #[[-0.70710678 -1.         -0.70710678]\n",
        " # [ 0.          0.          0.        ]\n",
        "  #[ 0.70710678  1.          0.70710678]]]\n",
        "  if type == 0:\n",
        "    points = np.arange(-1,1,2/n_in)\n",
        "    points_dim = [np.array(points) for i in range(1,dim+1)]\n",
        "    x = np.meshgrid(*points_dim)\n",
        "    x = np.asarray(x)\n",
        "    points_b = np.linspace(-1.0,1.0,num = n_b )\n",
        "    points_out = [points_b for i in range(1,dim+1)]\n",
        "    points_out = np.meshgrid(*points_out)\n",
        "    y = np.divide(points_out,LA.norm(points_out,axis =0),where=LA.norm(points_out,axis =0) !=0)\n",
        "    y = np.asarray(y)\n",
        "  elif type == 1:\n",
        "    print('Hello')\n",
        "\n",
        "  return [x,y];\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ynu6-A6jFQKo",
        "colab_type": "code",
        "outputId": "448eca52-9a06-4ec0-e4ae-284db3912142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "x= grid_sampling(0,2,2,3)\n",
        "data(x[0],x[1])\n",
        "#print(x.shape())\n",
        "#print(y[2][0,0,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[-1.  0.]\n",
            "  [-1.  0.]]\n",
            "\n",
            " [[-1. -1.]\n",
            "  [ 0.  0.]]]\n",
            "-1.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "-1.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "42\n",
            "[-1.0, -1.0]\n",
            "0.25\n",
            "42\n",
            "[0.0, -1.0]\n",
            "0.0\n",
            "42\n",
            "[-1.0, 0.0]\n",
            "0.0\n",
            "42\n",
            "[0.0, 0.0]\n",
            "-0.25\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}