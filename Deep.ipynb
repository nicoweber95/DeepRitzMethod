{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicoweber95/DeepRitzMethod/blob/master/Deep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AZshiOJuJ2l",
        "colab_type": "text"
      },
      "source": [
        "We want solve the following Dirichlet boundary problem: \\\\\n",
        "$-\\Delta u = 0$ in $\\Omega$ \\\\\n",
        "$u = 0$ in $\\partial \\Omega$ \\\\\n",
        "$\\Omega$ = \\{ x  $\\in$ $\\mathbb{R}^n$  | $\\sum_{i=1}^{n} x_i^2 \\leq 1$} \\\\\n",
        "exact solution: $\\frac{1}{2n}(\\sum_{i=1}^{n} x_i^2 -1 )$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fth1SRAMrEH_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebc4842f-eca0-45c8-8daf-7af397ddbe04"
      },
      "source": [
        "#from __future__import absolute_import, division, print_function, unicode_literals\n",
        "#example 3.1: The Poisson equation in two dimensions\n",
        "try:\n",
        "  # default tensorflow is 1.15\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import numpy as np\n",
        "from numpy import linalg as LA\n",
        "import itertools as it\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import tensorflow as tf\n",
        "# backend: create own activation functions, layers\n",
        "from tensorflow.keras import backend as K \n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "class RitzNet(Model):\n",
        "  def __init__(self,m,dim):\n",
        "    super(RitzNet, self).__init__()\n",
        "    self.m = m\n",
        "    self.dim = dim\n",
        "# test example for dimension 2,3 and 8; For later: make dimension variabel\n",
        "    if self.dim == 2:\n",
        "      self.l0 = Flatten()\n",
        "      self.l1 = Dense(1,activation = a_three)\n",
        "      #self.l1 = Dense(self.m, activation = a_three)\n",
        "      #self.l2 = Dense(1, input_dim = self.m,activation = a_three)\n",
        "      #self.l3 = Dense(self.m)\n",
        "    elif seld.dim ==3:\n",
        "      self.l1 = Dense(m, activation = a_three)\n",
        "      self.l2 = Dense(m, activation = a_three)\n",
        "      self.l3 = Dense(m, activation = a_three)\n",
        "      self.l4 = Dense(self.m)\n",
        "    elif self.dim == 8:\n",
        "      self.l1 = Dense(m, activation = a_three)\n",
        "      self.l2 = Dense(m, activation = a_three)\n",
        "      self.l3 = Dense(m, activation = a_three)\n",
        "      self.l4 = Dense(m, activation = a_three)\n",
        "      #self.l5 = Dense(self.m)\n",
        "  def call(self,x):\n",
        "    if self.dim == 2:\n",
        "      #print(x)\n",
        "      x = self.l0(x)\n",
        "      x = self.l1(x)\n",
        "      return x\n",
        "      #print(1)\n",
        "      #x = self.l2(x)\n",
        "      #print(2)\n",
        "      #return  self.l3(x)\n",
        "    elif seld.dim ==3:\n",
        "      x = self.l1(x)\n",
        "      x = self.l2(x)\n",
        "      x = self.l3(x)\n",
        "      return  self.l4(x)\n",
        "    elif self.dim == 8:\n",
        "      x = self.l1(x)\n",
        "      x = self.l2(x)\n",
        "      x = self.l3(x)\n",
        "      x = self.l4(x)\n",
        "      return  self.l5(x)\n",
        "\n",
        "#define own activation function \n",
        "def a_three(x):\n",
        "  return K.relu\n",
        "  #return K.ReLU(np.power(x,3))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKpD27wPYW9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exact_function(x,n):\n",
        "  func = np.zeros(1)\n",
        "  for i in range(0,n):\n",
        "    func += x[i]**2\n",
        "  func += -1\n",
        "  func /= (2*n)\n",
        "  return func\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4eicNEkFKFO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "fc3663bb-9f98-4583-b402-76ed26d612ec"
      },
      "source": [
        "# question: cann loss fm/keras-team/keras/issues/2121#issuecomment-214551349\n",
        "def penalized_loss\n",
        "#(unction only take two argumensts\n",
        "# see https://github.cosample_strategy):\n",
        "    def loss(y_true, y_pred):\n",
        "        return K.mean(K.square(y_pred - y_true) - K.square(y_true - noise), axis=-1)\n",
        "    return loss\n",
        "\n",
        "\n",
        "input1 = Input(batch_shape=(batch_size, timesteps, features))\n",
        "lstm =  LSTM(features, stateful=True, return_sequences=True)(input1)\n",
        "output1 = TimeDistributed(Dense(features, activation='sigmoid'))(lstm)\n",
        "output2 = TimeDistributed(Dense(features, activation='sigmoid'))(lstm)\n",
        "model = Model(input=[input1], output=[output1, output2])\n",
        "model.compile(loss=[penalized_loss(noise=output2), penalized_loss(noise=output1)], optimizer='rmsprop')\n",
        "def cal"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-1015f7e261f1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def penalized_loss\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKEdOOj3KHRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(model,dimension,x_in,x_out,lam):\n",
        "  dim_in = x_in.shape[0]\n",
        "  dim_out = x_out.shape[0]\n",
        "  \n",
        "  loss = np.zeros(1)\n",
        "  regularization = np.zeros(1)\n",
        "  eps = 0.0001\n",
        "  for j in it.product(*map(range,x_in.shape[1:])):\n",
        "    #y = model([x_in[i][j] for i in range(dim_in)],dimension)\n",
        "    p = [x_in[i][j] for i in range(dim_in)]\n",
        "    p = np.array(p)\n",
        "    p = p.reshape(-1)\n",
        "    #print(p.shape)\n",
        "    #hier ist der Fehler iwo\n",
        "    #print([x_in[i][j] for i in range(dim_in)])\n",
        "    #y = model([x_in[i][j] for i in range(dim_in)])\n",
        "    y = model(p)\n",
        "    x_grad = np.zeros(dim_in)\n",
        "    for i in range(dim_in):\n",
        "      print(model(x_in[i][j])) \n",
        "      print(y.summary)\n",
        "      #x_grad[i] = (model(x_in[i][j]+eps) - y[i])/ eps\n",
        "      x_grad[i] = (model(x_in[i][j]+eps) - y)/ eps\n",
        "    loss += 0.5*(np.sum([x**2 for x in x_grad ]) - y)\n",
        "  loss /= dim_in \n",
        "  for j in it.product(*map(range,x_out.shape[1:])):\n",
        "    y = model([x_in[i][j] for i in range(dim_out)],dimension)\n",
        "    regularization += lam*y**2\n",
        "  regularization /= dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCIH6vwx4zFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://towardsdatascience.com/tensorflow-2-0-create-and-train-a-vanilla-cnn-on-google-colab-c7a0ac86d61b\n",
        "def grad(model,x_in,x_out):\n",
        "  x_in = np.array(x_in)\n",
        "  x_out = np.array(x_out)\n",
        "  #print(x_in.shape)\n",
        "  with tf.GradientTape() as tape:\n",
        "    #prediction1 = model(x_in)\n",
        "    #prediction2 = model(x_out)\n",
        "    loss = custom_loss(model,3,x_in,x_out,500)\n",
        "  return loss, tape.gradient(loss, model.trainable_variables)\n",
        "  #optimizer = tf.keras.optimizers.SGD\n",
        "  #optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cpZ6q7_NdWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data(x_in,x_out):\n",
        "  dimension = x_in.shape[0]\n",
        "  y_in  = np.zeros(x_in.shape[1:])\n",
        "    #for i in range(dimension):\n",
        "  for j in it.product(*map(range,x_in.shape[1:])):\n",
        "    print(42)\n",
        "    print([x_in[i][j] for i in range(dimension)])\n",
        "    y_in[j] = exact_function([x_in[i][j] for i in range(dimension)],dimension)\n",
        "    print(y_in[j])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcGaJ0MZOxeZ",
        "colab_type": "code",
        "outputId": "bffd86fb-ad01-48ac-9196-9b806f2b5ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "## Note: Rerunning this cell uses the same model variables\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "# Keep results for plotting\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "[x_in,x_out]= grid_sampling(0,2,2,3)\n",
        "#print(x_in)\n",
        "num_epochs = 201\n",
        "model = RitzNet(10,2)\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "  # Training loop - using batches of 32\n",
        "  for x, y in zip(x_in,x_out):\n",
        "    # Optimize the model\n",
        "    #print(x)\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "    #print(x.shape)\n",
        "    loss_value, grad = grad(model, [x[0][0],x[1][0]], [y[0][0],y[1][0]])\n",
        "    optimizer.apply_gradients(zip(grad, model.trainable_variables))\n",
        "\n",
        "    # Track progress\n",
        "    epoch_loss_avg(loss_value)  # Add current batch loss\n",
        "    # Compare predicted label to actual label\n",
        "    epoch_accuracy(y, model(x))\n",
        "\n",
        "  # End epoch\n",
        "  train_loss_results.append(epoch_loss_avg.result())\n",
        "  train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "  if epoch % 50 == 0:\n",
        "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
        "                                                                epoch_loss_avg.result(),\n",
        "                                                                epoch_accuracy.result()))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<function relu at 0x7f2da6f70730>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2db7eb5f65be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-93c9bc79a4cc>\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(model, x_in, x_out)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#prediction1 = model(x_in)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#prediction2 = model(x_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m#optimizer = tf.keras.optimizers.SGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-62f0fa787c2f>\u001b[0m in \u001b[0;36mcustom_loss\u001b[0;34m(model, dimension, x_in, x_out, lam)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m       \u001b[0;31m#x_grad[i] = (model(x_in[i][j]+eps) - y[i])/ eps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mx_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'summary'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYwJlK4MXA0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcNYmb6nZsVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grid_sampling(type,dim,n_in,n_b):\n",
        "#type: 0: uniform sampling, 1: random sampling\n",
        "#dim: dimension of domain\n",
        "#n_in: number points in domain interior for each dimension ( n_in*dim all in all)\n",
        "#n_out: number points on boundary for each dimension (n_out*dim all in all)\n",
        "#idea boundary: take the boundary [-1,1]^dim and normalize to one\n",
        "#example :x= grid_sampling(0,2,2,3)\n",
        "#print(x[0])\n",
        "#print(x[1])\n",
        "#[array([[-1.,  0.],\n",
        " #      [-1.,  0.]]), array([[-1., -1.],\n",
        "  #     [ 0.,  0.]])]\n",
        "#[[[-0.70710678  0.          0.70710678]\n",
        " # [-1.          0.          1.        ]\n",
        "  #[-0.70710678  0.          0.70710678]]\n",
        "\n",
        " #[[-0.70710678 -1.         -0.70710678]\n",
        " # [ 0.          0.          0.        ]\n",
        "  #[ 0.70710678  1.          0.70710678]]]\n",
        "  if type == 0:\n",
        "    points = np.arange(-1,1,2/n_in)\n",
        "    points_dim = [np.array(points) for i in range(1,dim+1)]\n",
        "    x = np.meshgrid(*points_dim)\n",
        "    x = np.asarray(x)\n",
        "    points_b = np.linspace(-1.0,1.0,num = n_b )\n",
        "    points_out = [points_b for i in range(1,dim+1)]\n",
        "    points_out = np.meshgrid(*points_out)\n",
        "    y = np.divide(points_out,LA.norm(points_out,axis =0),where=LA.norm(points_out,axis =0) !=0)\n",
        "    y = np.asarray(y)\n",
        "  elif type == 1:\n",
        "    print('Hello')\n",
        "\n",
        "  return [x,y];\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ynu6-A6jFQKo",
        "colab_type": "code",
        "outputId": "a380dd2b-2096-4e8c-9a94-9b8a01f17fe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "[x,y]= grid_sampling(0,2,3,3)\n",
        "#data(x[0],x[1])\n",
        "print(x)\n",
        "print(y)\n",
        "#print(y[2][0,0,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[-1.         -0.33333333  0.33333333]\n",
            "  [-1.         -0.33333333  0.33333333]\n",
            "  [-1.         -0.33333333  0.33333333]]\n",
            "\n",
            " [[-1.         -1.         -1.        ]\n",
            "  [-0.33333333 -0.33333333 -0.33333333]\n",
            "  [ 0.33333333  0.33333333  0.33333333]]]\n",
            "[[[-0.70710678  0.          0.70710678]\n",
            "  [-1.          0.          1.        ]\n",
            "  [-0.70710678  0.          0.70710678]]\n",
            "\n",
            " [[-0.70710678 -1.         -0.70710678]\n",
            "  [ 0.          0.          0.        ]\n",
            "  [ 0.70710678  1.          0.70710678]]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}